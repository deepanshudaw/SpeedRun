
# ğŸ“˜ Wikipedia SpeedRun AI

AI-powered Wikipedia speedruns using semantic embeddings + a minimal Tkinter GUI.

<p align="center">
  <img src="assets/gui_demo.png" width="550" alt="Wikipedia SpeedRun GUI demo" />
</p>

---

## ğŸ·ï¸ Badges

<p align="left">
  <img src="https://img.shields.io/badge/Python-3.10-blue.svg" />
  <img src="https://img.shields.io/github/stars/deepanshudaw/SpeedRun?style=social" />
  <img src="https://img.shields.io/github/repo-size/deepanshudaw/SpeedRun" />
  <img src="https://img.shields.io/github/last-commit/deepanshudaw/SpeedRun" />
  <img src="https://img.shields.io/github/issues/deepanshudaw/SpeedRun" />
  <img src="https://img.shields.io/github/issues-pr/deepanshudaw/SpeedRun" />
</p>

---

## ğŸ§  Overview

This project implements a **Wikipedia speedrunning agent**:

- At each step, it scrapes all outgoing links from the current article.
- It embeds each candidate article using a **SentenceTransformer (MiniLM-L6-v2)**.
- It chooses the next page whose embedding is **closest** to the target page.
- It repeats until it reaches the target or gets stuck.

You can watch it run:

- in a **Tkinter GUI** (live timer, live path, status labels), or  
- in a simple **terminal interface**.

---

## ğŸ–¼ï¸ Screenshots

Main GUI:

<p align="center">
  <img src="assets/gui_blue_theme.png" width="600" alt="Main GUI" />
</p>

Speedrun in progress:

<p align="center">
  <img src="assets/gui_running.png" width="600" alt="Speedrun running" />
</p>

Live path preview:

<p align="center">
  <img src="assets/path_demo.png" width="600" alt="Path preview" />
</p>

---

## ğŸš€ Features

- **Semantic navigation**  
  - Each hop is chosen via cosine similarity  
    \[
    \text{next} = \arg\max \cos(\text{embedding(link)}, \text{embedding(target)})
    \]

- **Live GUI**  
  - Current page, step, links clicked  
  - Live timer from start to finish  
  - Path display like:  
    `One_Piece â†’ Burger_King â†’ Hamburger â†’ â€¦`

- **Optimised pipeline**  
  - Batched embedding (single model call per step)  
  - HTML + embedding caching  
  - Target embedding computed once per run  

---

## ğŸ“‚ Project Structure

```text
SpeedRun/
â”œâ”€â”€ scraping.py        # Wikipedia HTML fetch + link extraction
â”œâ”€â”€ embeddings.py      # SentenceTransformer loading, caching, batched encoding
â”œâ”€â”€ speedrun.py        # Core navigation logic (choose_next_link, speedrun)
â”œâ”€â”€ game_speedrun.py   # Terminal-based live speedrun
â”œâ”€â”€ tk_speedrun.py     # Tkinter GUI with live timer + path
â”œâ”€â”€ assets/            # Screenshots used in README
â”‚   â”œâ”€â”€ gui_demo.png
â”‚   â”œâ”€â”€ gui_blue_theme.png
â”‚   â”œâ”€â”€ gui_running.png
â”‚   â””â”€â”€ path_demo.png
â””â”€â”€ README.md


â¸»

ğŸ”§ Installation

python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

If you donâ€™t have a requirements.txt yet, a minimal one would be:

sentence-transformers
numpy
beautifulsoup4
requests

(Tkinter is included with most Python installs on macOS/Linux.)

â¸»

â–¶ï¸ Running the GUI

python tk_speedrun.py

Then in the window:
	â€¢	Set Source Page (e.g., One Piece)
	â€¢	Set Target Page (e.g., Burger King)
	â€¢	Click Start Speedrun

Youâ€™ll see:
	â€¢	Current page
	â€¢	Step number
	â€¢	Links clicked
	â€¢	Elapsed time
	â€¢	The path evolving live in the text box.

â¸»

â–¶ï¸ Running the Terminal Version

python game_speedrun.py

This prints:
	â€¢	current article
	â€¢	number of links clicked so far
	â€¢	elapsed time
	â€¢	final path at the end.

â¸»

ğŸ§ª Technical Walkthrough

Embeddings
	â€¢	Uses sentence-transformers with all-MiniLM-L6-v2.
	â€¢	For each page:
	â€¢	Fetch HTML via requests
	â€¢	Extract 1â€“2 intro paragraphs with BeautifulSoup
	â€¢	Encode intro text to a 384-dimensional vector

Batching

Instead of encoding each candidate link separately, links are batched:

embeddings = model.encode(texts, batch_size=32)

This significantly reduces overhead when a page has many links.

Navigation Logic
	1.	Compute target embedding once.
	2.	For current page:
	â€¢	scrape outgoing links
	â€¢	fetch + embed candidates (batched, cached)
	â€¢	compute cosine similarity to target
	â€¢	pick best-scoring link
	3.	Stop when:
	â€¢	target reached
	â€¢	max steps exceeded
	â€¢	or we hit loops / no candidates.

â¸»

ğŸ§­ Possible Extensions
	â€¢	Beam search or multi-path exploration
	â€¢	Pre-crawled subgraph of Wikipedia in a local DB / graph DB
	â€¢	Streamlit web UI
	â€¢	Visual graph of the path
	â€¢	Heuristics to avoid â€œtopic dead-endsâ€
	â€¢	Compare greedy vs random vs BFS shortest path

â¸»

âœï¸ Author

Deepanshu Dawande
AI / ML Engineer â€¢ LLM Systems & Tooling
